{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import  torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler #\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/PedroSci/Documents/Churn-Modelling/Exp1/'\n",
    "NUM_TRAIN = 50000\n",
    "NUM_VAL = 5000\n",
    "NUM_TEST = 5000\n",
    "MINIBATCH_SIZE= 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos un procesamiento a las imagenes, en este caso solo se pasaron a tensores de torch y ademas se normalizaron, como las imagenes se encuentran en un formato RGB se tiene cada una con  una normalizacion $\\frac{X-\\mu}{\\sigma}$; donde \n",
    "\n",
    "* $[\\mu_R, \\mu_G, \\mu_B] = [0.491,0.482,0.447]$\n",
    "* $[\\sigma_R, \\sigma_G, \\sigma_B]=[0.247,0.243,0.241]$\n",
    "\n",
    "**Nota:** Lo adecuado es calcular la media y la varianza de cada imagen en su canal respectivo, para este caso como el conjunto de imagenes ya se encuentra estudiado, se sabe que estos son sus valores reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cifar = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.491,0.482,0.447], [0.247,0.243,0.241])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Creacion del objeto como dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```root: str,\n",
    "    train: bool = True,\n",
    "    transform: ((...) -> Any) | None = None,\n",
    "    target_transform: ((...) -> Any) | None = None,\n",
    "    download: bool = False\n",
    "```\n",
    "\n",
    "```\n",
    "(dataset: Dataset[T_co@DataLoader], batch_size: int | None = 1, shuffle: bool | None = None, sampler: Sampler | Iterable | None = None, batch_sampler: Sampler[List] | Iterable[List] | None = None, num_workers: int = 0, collate_fn: _collate_fn_t | None = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: _worker_init_fn_t | None = None, multiprocessing_context: Any | None = None, generator: Any | None = None, *, prefetch_factor: int | None = None, persistent_workers: bool = False, pin_memory_device: str = \"\") -> None\n",
    "dataset (Dataset): dataset from which to load the data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_train = datasets.CIFAR10(root=DATA_PATH, train=True, download=True,transform=transform_cifar)\n",
    "train_loader  = DataLoader(dataset=cifar10_train, batch_size=MINIBATCH_SIZE, sampler=sampler.SubsetRandomSampler(indices=range(NUM_TRAIN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(root=DATA_PATH, train=False, download=True,transform=transform_cifar)\n",
    "val_loader  = DataLoader(dataset=cifar10_val, batch_size=MINIBATCH_SIZE, sampler=sampler.SubsetRandomSampler(indices=range(NUM_VAL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_test = datasets.CIFAR10(root=DATA_PATH, train=False, download=True,transform=transform_cifar)\n",
    "test_loader  = DataLoader(dataset=cifar10_test, batch_size=MINIBATCH_SIZE, sampler=sampler.SubsetRandomSampler(indices=range(NUM_TEST,len(cifar10_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/PedroSci/Documents/Churn-Modelling/Exp1/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.241])\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU disponible')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('GPU no siponible, se hara uso del CPU')\n",
    "    device = torch.device('cpu`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Sequiential'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m nfeatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m \u001b[38;5;66;03m# 3 canales (RGB) * 32 (large in pixels) * 32 (with in pixels)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequiential\u001b[49m(\n\u001b[1;32m      9\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m     10\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39mnfeatures, out_features \u001b[38;5;241m=\u001b[39m hidden1), nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39mhidden1,   out_features \u001b[38;5;241m=\u001b[39m hiden), nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39mhiden,   out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model1\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     16\u001b[0m train(model\u001b[38;5;241m=\u001b[39mmodel1, train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, val_loader\u001b[38;5;241m=\u001b[39mval_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Sequiential'"
     ]
    }
   ],
   "source": [
    "hidden1 = 256\n",
    "hiden = 256\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "nfeatures = 3*32*32 # 3 canales (RGB) * 32 (large in pixels) * 32 (with in pixels)\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=nfeatures, out_features = hidden1), nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden1,   out_features = hiden), nn.ReLU(),\n",
    "    nn.Linear(in_features=hiden,   out_features = 10))\n",
    "\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr = lr)\n",
    "\n",
    "train(model=model1, train_loader=train_loader, val_loader=val_loader, optimizer=optimizer, epochs = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Churn-Modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
